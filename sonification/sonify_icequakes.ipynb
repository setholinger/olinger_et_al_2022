{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.fft import fft, fftfreq, ifft\n",
    "import datetime\n",
    "import numpy as np\n",
    "import glob\n",
    "import pyasdf\n",
    "import h5py\n",
    "import pickle\n",
    "import wave\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "file = \"/media/Data/Data/XC/MSEED/noIR/PIG4/HHZ/2012-05-09.PIG4.HHZ.noIR.MSEED\"\n",
    "st_raw = obspy.read(file)\n",
    "\n",
    "# resample\n",
    "fs = 21\n",
    "st_raw.resample(fs)\n",
    "\n",
    "# make copies\n",
    "st_broad = st_raw.copy()\n",
    "st_low = st_raw.copy()\n",
    "st_high = st_raw.copy()\n",
    "\n",
    "# filter to a few bands\n",
    "low_cut = 0.001\n",
    "high_cut = 10\n",
    "st_broad.filter(\"bandpass\", freqmin=low_cut, freqmax=10)\n",
    "st_low.filter(\"bandpass\", freqmin=low_cut, freqmax=1)\n",
    "st_high.filter(\"bandpass\",freqmin=1,freqmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trim to times of interest\n",
    "starttime = obspy.UTCDateTime(2012,5,9,3)\n",
    "endtime = obspy.UTCDateTime(2012,5,9,5)\n",
    "st_broad.trim(starttime=starttime,endtime=endtime)\n",
    "st_low.trim(starttime=starttime,endtime=endtime)\n",
    "st_high.trim(starttime=starttime,endtime=endtime)\n",
    "\n",
    "# make a plot\n",
    "fig,ax = plt.subplots(2,1,figsize=(25,10))\n",
    "times = [t.datetime for t in st_broad[0].times(type=\"utcdatetime\")]\n",
    "ax[0].plot(times,st_high[0].data)\n",
    "ax[1].plot(times,st_low[0].data)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()\n",
    "\n",
    "# write out audio file\n",
    "st_broad.write('../outputs/audio/day_test.wav', format='WAV', framerate=70000, rescale=True, width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# zoom in on a low-frequency-first sounding event\n",
    "#starttime = obspy.UTCDateTime(2012,5,9,10,50)\n",
    "#endtime = obspy.UTCDateTime(2012,5,9,11,20)\n",
    "starttime = obspy.UTCDateTime(2012,5,9,3)\n",
    "endtime = obspy.UTCDateTime(2012,5,9,4)\n",
    "swell_event = st_broad.copy().trim(starttime=starttime,endtime=endtime)\n",
    "\n",
    "# zoom in on a high-frequency-first event\n",
    "starttime = obspy.UTCDateTime(2012,5,9,17,30)\n",
    "endtime = obspy.UTCDateTime(2012,5,9,18)\n",
    "fg_event = st_broad.copy().trim(starttime=starttime,endtime=endtime)\n",
    "\n",
    "# put data into a crude list\n",
    "data = [swell_event,fg_event]\n",
    "\n",
    "# make plot\n",
    "fig,ax = plt.subplots(2,2,figsize=(20,10))\n",
    "\n",
    "for i,st in enumerate(data):\n",
    "    times = [t.datetime for t in st[0].times(\"UTCDateTime\")]\n",
    "    ticks = [times[len(times)//8],times[len(times)//4],times[len(times)//8*3],times[len(times)//2],times[len(times)//8*5],times[len(times)//4*3],times[len(times)//8*7],times[len(times)-1]]\n",
    "    ax[0][i].plot(times,st[0].data*1000,'k')\n",
    "    ax[0][i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "    ax[0][i].grid(True)\n",
    "    ax[0][i].set_ylabel(\"Velocity (mm/s)\")    \n",
    "    ax[0][i].set_title(\"Time domain signal\")\n",
    "\n",
    "    # make spectrogram\n",
    "    win_len = 30\n",
    "    f,t,s = spectrogram(st[0].data*1000, fs=fs, nperseg=win_len*fs)\n",
    "\n",
    "    # plot spectrogram \n",
    "    times = [st[0].stats.starttime.datetime + datetime.timedelta(seconds=time) for time in t]\n",
    "    spec = ax[1][i].pcolor(times, np.log10(f), np.log10(s), vmin=np.log10(10e-11),vmax=np.log10(10e-5))\n",
    "    ax[1][i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "    ax[1][i].get_shared_x_axes().join(ax[0][i],ax[1][i])\n",
    "    ax[1][i].set_xticks(ticks)\n",
    "    ax[1][i].set_xlim([times[0],times[-1]])\n",
    "    ax[1][i].set_yticks([np.log10(low_cut),0,1])\n",
    "    ax[1][i].set_ylim([-1,1])\n",
    "    ax[1][i].set_yticklabels([\"$10^{-1}$\",\"$10^{0}$\",\"$10^{1}$\"])\n",
    "    ax[1][i].set_ylabel(\"Frequency (Hz)\")\n",
    "    ax[1][i].set_xlabel(\"Time\")\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.9, 0.1225, 0.025, 0.5])\n",
    "cbar = plt.colorbar(spec,label=\"PSD [(mm/s)$^2$/Hz]\",ticks=[-10,-8,-6,-4],cax=cbar_ax)\n",
    "cbar.ax.set_yticklabels(['$10^{-8}$','$10^{-8}$','$10^{-6}$','$10^{-4}$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get list of files\n",
    "station = \"PIG5\"\n",
    "files = glob.glob(\"/media/Data/Data/XC/MSEED/noIR/\"+station+\"/HHZ/*\")\n",
    "files.sort()\n",
    "\n",
    "# make empty stream for storage\n",
    "st = obspy.Stream()\n",
    "\n",
    "# read in each file\n",
    "for f in files:\n",
    "    st_temp = obspy.read(f)\n",
    "    \n",
    "    # downsample data to 2.1 Hz\n",
    "    st_temp.resample(2.1)\n",
    "        \n",
    "    # normalize to 1\n",
    "    st_temp[0].data = st_temp[0].data/max(abs(st_temp[0].data)) \n",
    "        \n",
    "    # add to stream \n",
    "    st += st_temp\n",
    "\n",
    "# filter to band of interest\n",
    "low_cut = 0.001\n",
    "st.filter(\"bandpass\", freqmin=low_cut, freqmax=1)\n",
    "\n",
    "# merge stream\n",
    "st.merge(fill_value='interpolate')\n",
    "\n",
    "# write out audio file\n",
    "st.write(\"../outputs/audio/\"+station+\"_HHZ_deployment.wav\", format='WAV', framerate=700000, rescale=True, width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract detection times for each event in the dataset\n",
    "ds = pyasdf.ASDFDataSet(\"/home/setholinger/Documents/rift_codes/outputs/detections/template_matching_catalog.h5\",mode='r')\n",
    "detection_times = []\n",
    "for event in ds.events:\n",
    "    detection_times.append(event.origins[0].time.datetime)\n",
    "del ds\n",
    "\n",
    "# load event waveforms\n",
    "waveform_file = h5py.File(\"/home/setholinger/Documents/rift_codes/outputs/stacking/waveforms_PIG2_0.01Hz.h5\",'r')\n",
    "waveforms = np.array(waveform_file['waveforms_0.01-1Hz'])\n",
    "waveform_file.close()\n",
    "\n",
    "# load clustering results\n",
    "cluster_file = h5py.File(\"/home/setholinger/Documents/rift_codes/outputs/clustering/2_cluster_results.h5\",\"r\")\n",
    "predictions = np.array(list(cluster_file[\"cluster_index\"]))\n",
    "centroids = list(cluster_file[\"centroids\"])\n",
    "cluster_file.close()\n",
    "\n",
    "# load the results of polarization analysis\n",
    "baz_file = open('/home/setholinger/Documents/rift_codes/outputs/locations/event_backazimuths_PIG1_PIG2_PIG3_PIG4_PIG5_distance_pca_fixed_centroid.pickle', \"rb\")\n",
    "b = pickle.load(baz_file)\n",
    "backazimuths = b.backazimuths\n",
    "baz_file.close()\n",
    "\n",
    "# subset the backazimuths for just dispersive events\n",
    "backazimuths = backazimuths[predictions==0]\n",
    "\n",
    "# subset detection times for just dispersive events\n",
    "detection_times = np.array(detection_times)[predictions == 0]\n",
    "\n",
    "# split into each spatial group\n",
    "rift_tip_indices = np.logical_and(backazimuths>=180,backazimuths<280)\n",
    "margin_indices = np.logical_and(backazimuths>=0,backazimuths<180)\n",
    "rift_margin_indices = np.logical_and(backazimuths>=280,backazimuths<360) \n",
    "\n",
    "# define function to pad with zeros to space events properly in time\n",
    "def get_timeseries(detection_times,waveforms,fs,starttime,endtime):\n",
    "    trace_len = waveforms.shape[1]\n",
    "    first_gap = detection_times[0]-starttime\n",
    "    first_gap_samples = int(np.round(first_gap.total_seconds()*fs))\n",
    "    timeseries = np.zeros(first_gap_samples)\n",
    "    gaps = np.diff(detection_times)\n",
    "    for i in range(len(gaps)):\n",
    "        gap_samples = int(np.round(gaps[i].total_seconds()*fs)-trace_len)\n",
    "        if gap_samples < 0:\n",
    "            timeseries = np.concatenate((timeseries,waveforms[i][:-(trace_len+gap_samples)]))\n",
    "        else:\n",
    "            timeseries = np.concatenate((timeseries,waveforms[i],np.zeros(gap_samples)))\n",
    "    timeseries = np.concatenate((timeseries,waveforms[-1]))\n",
    "    final_gap = endtime - detection_times[-1]\n",
    "    final_gap_samples = int(np.round(final_gap.total_seconds()*fs)+trace_len)\n",
    "    timeseries = np.concatenate((timeseries,np.zeros(final_gap_samples)))\n",
    "    return timeseries\n",
    "\n",
    "# pad with zeros so the events are appropriately spaced in time\n",
    "fs = 2.1\n",
    "starttime = datetime.datetime(2012,1,1,0,0)\n",
    "endtime = datetime.datetime(2014,1,1,0,0)\n",
    "rift_tip_timeseries = get_timeseries(detection_times[rift_tip_indices],waveforms[rift_tip_indices],fs,starttime,endtime)\n",
    "margin_timeseries = get_timeseries(detection_times[margin_indices],waveforms[margin_indices],fs,starttime,endtime)\n",
    "rift_margin_timeseries = get_timeseries(detection_times[rift_margin_indices],waveforms[rift_margin_indices],fs,starttime,endtime)\n",
    "\n",
    "# define function to rescale each timeseries and write to an audio file\n",
    "def write_wav(filename,data,sample_width,framerate):\n",
    "    WIDTH2DTYPE = {1: '<u1', 2: '<i2',4: '<i4'}\n",
    "    w = wave.open(filename, 'wb')\n",
    "    w.setparams((1, sample_width, framerate, len(data), 'NONE','not compressed'))\n",
    "    dtype = WIDTH2DTYPE[sample_width]\n",
    "    data = data.astype(np.float64)\n",
    "    maxint = 2 ** (sample_width * 8 - 1) - 1\n",
    "    data = data / abs(data).max() * maxint\n",
    "    data = np.require(data, dtype=dtype)\n",
    "    w.writeframes(data.tobytes())\n",
    "    return\n",
    "\n",
    "# write each timeseries to audio file\n",
    "sample_width = 4\n",
    "framerate = 4.2e5\n",
    "write_wav(\"../outputs/audio/rift_tip.wav\",rift_tip_timeseries,sample_width,framerate)\n",
    "write_wav(\"../outputs/audio/margin.wav\",margin_timeseries,sample_width,framerate)\n",
    "write_wav(\"../outputs/audio/rift_margin.wav\",rift_margin_timeseries,sample_width,framerate)\n",
    "\n",
    "# read each audio file\n",
    "\n",
    "# map audio to stereo pan positions based on mean backazimuth for each spatial group\n",
    "\n",
    "# combine audio files\n",
    "\n",
    "# save final audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rift_audio = AudioSegment.from_file(\"../outputs/audio/rift_tip.wav\")\n",
    "margin_audio = AudioSegment.from_file(\"../outputs/audio/margin.wav\")\n",
    "rift_margin_audio = AudioSegment.from_file(\"../outputs/audio/rift_margin.wav\")\n",
    "\n",
    "# calculate median backazimuth for each group\n",
    "rift_tip_backazimuth = np.median(backazimuths[rift_tip_indices])\n",
    "margin_backazimuth = np.median(backazimuths[margin_indices])\n",
    "rift_margin_backazimuth = np.median(backazimuths[rift_margin_indices])\n",
    "\n",
    "# calculate the pan\n",
    "ice_front_backazimuth = 280\n",
    "rift_tip_pan = (ice_front_backazimuth - rift_tip_backazimuth)/180\n",
    "margin_pan = (ice_front_backazimuth - rift_tip_backazimuth)/180\n",
    "rift_margin_pan = (ice_front_backazimuth - rift_tip_backazimuth)/180\n",
    "\n",
    "# pan audio based on mean backazimuth, assuming the listener is facing from the array towards the ice front\n",
    "rift_tip_panned = rift_audio.pan(rift_tip_pan)\n",
    "rift_tip_panned = rift_audio.pan(rift_tip_pan)\n",
    "rift_tip_panned = rift_audio.pan(rift_tip_pan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define function to pad with zeros to space events properly in time\n",
    "def get_timeseries(detection_times,waveforms,fs,starttime,endtime):\n",
    "    trace_len = waveforms.shape[1]\n",
    "    first_gap = detection_times[0]-starttime\n",
    "    first_gap_samples = int(np.round(first_gap.total_seconds()*fs))\n",
    "    timeseries = np.zeros(first_gap_samples)\n",
    "    gaps = np.diff(detection_times)\n",
    "    for i in range(len(gaps)):\n",
    "        gap_samples = int(np.round(gaps[i].total_seconds()*fs)-trace_len)\n",
    "        if gap_samples < 0:\n",
    "            timeseries = np.concatenate((timeseries,waveforms[i][:-(trace_len+gap_samples)]))\n",
    "        else:\n",
    "            timeseries = np.concatenate((timeseries,waveforms[i],np.zeros(gap_samples)))\n",
    "    timeseries = np.concatenate((timeseries,waveforms[-1]))\n",
    "    final_gap = endtime - detection_times[-1]\n",
    "    final_gap_samples = int(np.round(final_gap.total_seconds()*fs)+trace_len)\n",
    "    timeseries = np.concatenate((timeseries,np.zeros(final_gap_samples)))\n",
    "    return timeseries\n",
    "\n",
    "# pad with zeros so the events are appropriately spaced in time\n",
    "fs = 2.1\n",
    "starttime = datetime.datetime(2012,1,1,0,0)\n",
    "endtime = datetime.datetime(2014,1,1,0,0)\n",
    "rift_tip_timeseries = get_timeseries(detection_times[rift_tip_indices],waveforms[rift_tip_indices],fs,starttime,endtime)\n",
    "margin_timeseries = get_timeseries(detection_times[margin_indices],waveforms[margin_indices],fs,starttime,endtime)\n",
    "rift_margin_timeseries = get_timeseries(detection_times[rift_margin_indices],waveforms[rift_margin_indices],fs,starttime,endtime)\n",
    "\n",
    "# define function to rescale each timeseries and write to an audio file\n",
    "def write_wav(filename,data,sample_width,framerate):\n",
    "    w = wave.open(filename, 'wb')\n",
    "    w.setparams((1, sample_width, framerate, len(data), 'NONE','not compressed'))\n",
    "    dtype = WIDTH2DTYPE[sample_width]\n",
    "    data = data.astype(np.float64)\n",
    "    maxint = 2 ** (sample_width * 8 - 1) - 1\n",
    "    data = data / abs(data).max() * maxint\n",
    "    data = np.require(data, dtype=dtype)\n",
    "    w.writeframes(data.tobytes())\n",
    "    return\n",
    "\n",
    "# write each timeseries to audio file\n",
    "sample_width = 4\n",
    "framerate = 4.2e5\n",
    "WIDTH2DTYPE = {1: '<u1', 2: '<i2',4: '<i4'}\n",
    "write_wav(\"../outputs/audio/rift_tip.wav\",rift_tip_timeseries,sample_width,framerate)\n",
    "write_wav(\"../outputs/audio/margin.wav\",margin_timeseries,sample_width,framerate)\n",
    "write_wav(\"../outputs/audio/rift_margin.wav\",rift_margin_timeseries,sample_width,framerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naively try to shift frequencies for a cosine\n",
    "fs = np.pi/16\n",
    "wave = np.cos(np.arange(0,8*np.pi,np.pi/16))\n",
    "t = np.arange(0,len(wave)*1/fs,1/fs)\n",
    "wave_fft = fft(wave)\n",
    "f = fftfreq(len(wave),fs)\n",
    "wave_fft_pos = wave_fft[len(wave_fft)//2:]\n",
    "wave_fft_neg = wave_fft[:len(wave_fft)//2]\n",
    "wave_fft_shift_down = np.concatenate((wave_fft_neg,np.zeros(100),wave_fft_pos))\n",
    "wave_ifft_shift_down = ifft(wave_fft_shift_down)\n",
    "t_down = np.arange(0,len(wave_ifft_shift_down)*1/fs-1,1/fs)\n",
    "wave_fft_shift_up = np.concatenate((wave_fft_neg[:-10],wave_fft_pos[10:]))\n",
    "wave_ifft_shift_up = ifft(wave_fft_shift_up)\n",
    "t_up = np.arange(0,len(wave_ifft_shift_up)*1/fs,1/fs)\n",
    "\n",
    "# plot result\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(t,wave,label='Original signal')\n",
    "plt.plot(t_down,wave_ifft_shift_down,label='Frequency shifted down')\n",
    "plt.plot(t_up,wave_ifft_shift_up,label='Frequency shifted up')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# try the naive method with real data\n",
    "fs = 2.1\n",
    "wave = margin_waveforms[1]\n",
    "t = np.arange(0,len(wave)*1/fs,1/fs)\n",
    "wave_fft = fft(wave)\n",
    "f = fftfreq(len(wave),fs)\n",
    "wave_fft_pos = wave_fft[len(wave_fft)//2:]\n",
    "wave_fft_neg = wave_fft[:len(wave_fft)//2]\n",
    "wave_fft_shift_up = np.concatenate((wave_fft_neg[:-500],wave_fft_pos[500:]))\n",
    "f_up = fftfreq(len(wave_fft_shift_up),1/fs)\n",
    "wave_ifft_shift_up = ifft(wave_fft_shift_up)\n",
    "t_up = np.arange(0,len(wave_ifft_shift_up)*1/fs,1/fs)\n",
    "\n",
    "# plot result- note that this is a bad way to shift frequencies up, because it destroys part of the spectra and causes signal degradation at large shifts\n",
    "fig,ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].plot(f[:len(f)//2+1],np.abs(wave_fft[:len(wave_fft)//2+1]),label='Original signal')\n",
    "ax[0].plot(f_up[:len(f_up)//2+1],np.abs(wave_fft_shift_up[:len(wave_fft_shift_up)//2+1]),label='Frequency shifted up')\n",
    "ax[0].legend()\n",
    "ax[1].plot(t,wave,label='Original signal')\n",
    "ax[1].plot(t_up,wave_ifft_shift_up,label='Frequency shifted up')\n",
    "ax[1].legend()\n",
    "plt.show()\n",
    "\n",
    "# try a more intelligent method for a cosine\n",
    "fs = 1/(np.pi/16)\n",
    "wave = np.cos(np.arange(0,8*np.pi,np.pi/16))\n",
    "t = np.arange(0,len(wave)*1/fs,1/fs)\n",
    "wave_fft = fft(wave)\n",
    "f = fftfreq(len(wave),fs)\n",
    "wave_up = wave * np.cos(np.arange(0,8*np.pi,np.pi/16)*100)\n",
    "wave_fft_shift_up = fft(wave_up)\n",
    "f_up = fftfreq(len(wave_fft_shift_up),fs)\n",
    "wave_fft_shift_up[np.logical_and(f_up > 0.01,f_up < 0.02)] = 0\n",
    "wave_fft_shift_up[np.logical_and(f_up < -0.01,f_up > -0.02)] = 0\n",
    "wave_ifft_shift_up = ifft(wave_fft_shift_up)\n",
    "t_up = np.arange(0,len(wave_ifft_shift_up)*1/fs,1/fs)\n",
    "\n",
    "# plot result- note that we quickly run up against the nyquist frequency, so this isn't a good method either...\n",
    "fig,ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].plot(f[:len(f)//2],np.abs(wave_fft[:len(wave_fft)//2]),label='Original signal')\n",
    "ax[0].plot(f_up[:len(f)//2],np.abs(wave_fft_shift_up[:len(wave_fft_shift_up)//2]),label='Frequency shifted up')\n",
    "ax[0].legend()\n",
    "ax[1].plot(t,wave,label='Original signal')\n",
    "ax[1].plot(t_up,wave_ifft_shift_up,label='Frequency shifted up')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
